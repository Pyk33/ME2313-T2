{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/v85b1fvn22v4g_yk95dpk_s80000gn/T/ipykernel_2001/135098645.py:24: DtypeWarning: Columns (9,14,19,22,24,29,32,34,39,40,41,42,43,44,45,48,52,75,87,91,99,110,112,113,135,139,140,141,143,145,156,157) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(input_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved to /Users/valdemarhane/Documents/GitHub/ME2313-T2/ME2313-T2/Cleaned Data/RT.IRS_Clean_v1.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Module 1: Imports RT.IRS_data.csv and cleans it by removing all rows which does  not have \n",
    "# data in the \"Event\"-column. Further it removes all headers and corresponding \n",
    "# columns which is empty (no data).\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths using relative paths\n",
    "input_file_path = \"CME data import/Categorized Data/RT.IRS_Data.csv\"\n",
    "output_file_path = \"Cleaned Data/RT.IRS_Clean_v1.csv\"\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "\n",
    "# Construct absolute file paths\n",
    "input_file_path = os.path.join(current_directory, input_file_path)\n",
    "output_file_path = os.path.join(current_directory, output_file_path)\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(input_file_path)\n",
    "\n",
    "# Remove rows where the \"Event\" column is empty\n",
    "data = data.dropna(subset=['Event'])\n",
    "\n",
    "# Remove columns where all values are NaN after removing empty rows\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "# Remove rows where \"Event\" column starts with two numbers\n",
    "data = data[~data['Event'].astype(str).str.match(r'^\\d{2}')]\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Data cleaned and saved to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned, sorted, and saved to /Users/valdemarhane/Documents/GitHub/ME2313-T2/ME2313-T2/Cleaned Data/RT.IRS_Clean_v1.csv\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 2: Sort the rows based on the \"Event\" column \n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Remove all rows where Conract Type is NOT InterestRateSwap\n",
    "data = data[data['Contract Type'] == 'InterestRateSwap']\n",
    "\n",
    "# Save the cleaned and sorted data to a new CSV file\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Data cleaned, sorted, and saved to\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables defined.\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 3: Define parameters\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Define the variables from the second sheet\n",
    "variables_info = {\n",
    "    \"Event\": \"string\",\n",
    "    \"Execution Timestamp\": \"datetime\",\n",
    "    \"Dissemination Time\": \"datetime\",\n",
    "    \"Cleared\": \"string\",\n",
    "    \"Collateralization\": \"string\",\n",
    "    \"End-User Exception\": \"string\",\n",
    "    \"Bespoke\": \"character\",\n",
    "    \"Block/Off facility\": \"character\",\n",
    "    \"Execution Venue\": \"string\",\n",
    "    \"UPI\": \"string\",\n",
    "    \"Product\": \"string\",\n",
    "    \"Contract Type\": \"string\",\n",
    "    \"Effective Date\": \"date\",\n",
    "    \"Maturity Date\": \"date\",\n",
    "    \"Upfront Payment\": \"int\",\n",
    "    \"Upfront Payment Currency\": \"string\",\n",
    "    \"Upfront Payment Date\": \"date\",\n",
    "    \"Settlement Currency\": \"string\",\n",
    "    \"Leg 1 Type\": \"string\",\n",
    "    \"Leg 1 Fixed Rate\": \"int\",\n",
    "    \"Leg 1 Floating Index\": \"string\",\n",
    "    \"Leg 1 Designated Maturity\": \"string\",\n",
    "    \"Leg 1 Spread\": \"float\",\n",
    "    \"Leg 1 Day Count Convention\": \"string\",\n",
    "    \"Leg 1 Notional\": \"int\",\n",
    "    \"Leg 1 Notional Currency\": \"string\",\n",
    "    \"Leg 1 Payment Frequency\": \"string\",\n",
    "    \"Leg1 Reset Frequency\": \"string\",\n",
    "    \"Leg 2 Type\": \"string\",\n",
    "    \"Leg 2 Fixed Rate\": \"float\",\n",
    "    \"Leg 2 Floating Index\": \"string\",\n",
    "    \"Leg 2 Designated Maturity\": \"string\",\n",
    "    \"Leg 2 Spread\": \"float\",\n",
    "    \"Leg 2 Day Count Convention\": \"string\",\n",
    "    \"Leg 2 Notional\": \"float\",\n",
    "    \"Leg 2 Notional Currency\": \"string\",\n",
    "    \"Leg 2 Payment Frequency\": \"string\",\n",
    "    \"Leg 2 Reset Frequency\": \"string\",\n",
    "    \"Embedded Option\": \"character\",\n",
    "    \"Option Strike Price\": \"float\",\n",
    "    \"Option Type\": \"string\",\n",
    "    \"Option Family\": \"string\",\n",
    "    \"Option Currency\": \"string\",\n",
    "    \"Option Premium\": \"float\",\n",
    "    \"Option Lockout Period\": \"date\",\n",
    "    \"Option Expiration Date\": \"date\",\n",
    "    \"Asset Class\": \"string\",\n",
    "    \"Rpt ID\": \"string\",\n",
    "    \"Prev Rpt ID\": \"string\",\n",
    "    \"Future Value Notional\": \"float\",\n",
    "    \"Contract Subtype\": \"string\"\n",
    "}\n",
    "\n",
    "print(\"Variables defined.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data adjusted and saved to /Users/valdemarhane/Documents/GitHub/ME2313-T2/ME2313-T2/Cleaned Data/RT.IRS_Clean_v2.csv\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 4: Adjust columns according to variables_info and save to CSV\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "for column, data_type in variables_info.items():\n",
    "    if column in data.columns:\n",
    "        if data_type == \"string\":\n",
    "            data[column] = data[column].astype(str)\n",
    "        elif data_type == \"int\":\n",
    "            # Convert to numeric with NaN for non-convertible values\n",
    "            data[column] = pd.to_numeric(data[column], errors='coerce')\n",
    "            # Optional: Fill NaN with a placeholder like 0 or -1\n",
    "            # data[column] = data[column].fillna(0).astype('Int64')\n",
    "        elif data_type == \"float\":\n",
    "            data[column] = pd.to_numeric(data[column], errors='coerce')\n",
    "        elif data_type == \"datetime\":\n",
    "            data[column] = pd.to_datetime(data[column], errors='coerce')\n",
    "        elif data_type == \"date\":\n",
    "            data[column] = pd.to_datetime(data[column], errors='coerce').dt.date\n",
    "        # Add more conditions as needed for other data types\n",
    "\n",
    "\n",
    "# Define the output file path for the cleaned data\n",
    "output_file_path = os.path.join(current_directory, \"Cleaned Data/RT.IRS_Clean_v2.csv\")\n",
    "\n",
    "# Save the adjusted data to a CSV file\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Data adjusted and saved to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: string\n",
      "       Event          Cleared     Collateralization End-User Exception  \\\n",
      "0  New Trade  Intend to Clear  Fully Collateralized                nan   \n",
      "1  New Trade  Intend to Clear  Fully Collateralized                nan   \n",
      "2  New Trade  Intend to Clear  Fully Collateralized                nan   \n",
      "3  New Trade  Intend to Clear  Fully Collateralized                nan   \n",
      "4  New Trade  Intend to Clear  Fully Collateralized                nan   \n",
      "\n",
      "           Execution Venue  UPI      Product     Contract Type  \\\n",
      "0  Registered Market - DCM  nan   IRS EUR 5Y  InterestRateSwap   \n",
      "1  Registered Market - DCM  nan   IRS EUR 5Y  InterestRateSwap   \n",
      "2  Registered Market - DCM  nan   IRS EUR 2Y  InterestRateSwap   \n",
      "3  Registered Market - DCM  nan   IRS EUR 2Y  InterestRateSwap   \n",
      "4  Registered Market - DCM  nan  IRS EUR 10Y  InterestRateSwap   \n",
      "\n",
      "  Upfront Payment Currency Settlement Currency  ... Leg 2 Notional Currency  \\\n",
      "0                      nan                 EUR  ...                     EUR   \n",
      "1                      nan                 EUR  ...                     EUR   \n",
      "2                      nan                 EUR  ...                     EUR   \n",
      "3                      nan                 EUR  ...                     EUR   \n",
      "4                      nan                 EUR  ...                     EUR   \n",
      "\n",
      "  Leg 2 Payment Frequency Leg 2 Reset Frequency Option Type Option Family  \\\n",
      "0                     MTH                   MTH         nan           nan   \n",
      "1                     MTH                   MTH         nan           nan   \n",
      "2                     MTH                   MTH         nan           nan   \n",
      "3                     MTH                   MTH         nan           nan   \n",
      "4                     MTH                   MTH         nan           nan   \n",
      "\n",
      "  Option Currency    Asset Class       Rpt ID Prev Rpt ID Contract Subtype  \n",
      "0             nan  Interest Rate  IRS22292351         nan              nan  \n",
      "1             nan  Interest Rate  IRS22292352         nan              nan  \n",
      "2             nan  Interest Rate  IRS22292353         nan              nan  \n",
      "3             nan  Interest Rate  IRS22292354         nan              nan  \n",
      "4             nan  Interest Rate  IRS22292355         nan              nan  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "\n",
      "Data Type: datetime\n",
      "  Execution Timestamp Dissemination Time\n",
      "0          2016-09-08         2016-09-08\n",
      "1          2016-09-08         2016-09-08\n",
      "2          2016-09-08         2016-09-08\n",
      "3          2016-09-08         2016-09-08\n",
      "4          2016-09-08         2016-09-08\n",
      "\n",
      "\n",
      "Data Type: character\n",
      "  Bespoke Block/Off facility Embedded Option\n",
      "0       N                  N               N\n",
      "1       N                  N               N\n",
      "2       N                  N               N\n",
      "3       N                  N               N\n",
      "4       N                  N               N\n",
      "\n",
      "\n",
      "Data Type: date\n",
      "  Effective Date Maturity Date Upfront Payment Date Option Lockout Period  \\\n",
      "0     2017-09-12    2022-09-12                  NaT                   NaT   \n",
      "1     2017-09-12    2022-09-12                  NaT                   NaT   \n",
      "2     2017-09-12    2019-09-12                  NaT                   NaT   \n",
      "3     2017-09-12    2019-09-12                  NaT                   NaT   \n",
      "4     2017-09-12    2027-09-12                  NaT                   NaT   \n",
      "\n",
      "  Option Expiration Date  \n",
      "0                    NaT  \n",
      "1                    NaT  \n",
      "2                    NaT  \n",
      "3                    NaT  \n",
      "4                    NaT  \n",
      "\n",
      "\n",
      "Data Type: int\n",
      "   Upfront Payment  Leg 1 Fixed Rate  Leg 1 Notional\n",
      "0              0.0             0.040     200000000.0\n",
      "1              0.0             0.040     200000000.0\n",
      "2              0.0             0.211     250000000.0\n",
      "3              0.0             0.211     250000000.0\n",
      "4              0.0             0.429      50000000.0\n",
      "\n",
      "\n",
      "Data Type: float\n",
      "   Leg 1 Spread  Leg 2 Fixed Rate  Leg 2 Spread  Leg 2 Notional  \\\n",
      "0           0.0               0.0           0.0     200000000.0   \n",
      "1           0.0               0.0           0.0     200000000.0   \n",
      "2           0.0               0.0           0.0     250000000.0   \n",
      "3           0.0               0.0           0.0     250000000.0   \n",
      "4           0.0               0.0           0.0      50000000.0   \n",
      "\n",
      "   Option Strike Price  Option Premium  Future Value Notional  \n",
      "0                  0.0             0.0                    0.0  \n",
      "1                  0.0             0.0                    0.0  \n",
      "2                  0.0             0.0                    0.0  \n",
      "3                  0.0             0.0                    0.0  \n",
      "4                  0.0             0.0                    0.0  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 5: Display DataFrame rows separated by data types\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Group columns by their data types\n",
    "columns_by_type = {}\n",
    "for col, dtype in variables_info.items():\n",
    "    if col in data.columns:\n",
    "        columns_by_type.setdefault(dtype, []).append(col)\n",
    "\n",
    "# Print the top 5 rows for each data type\n",
    "for dtype, cols in columns_by_type.items():\n",
    "    print(f\"Data Type: {dtype}\")\n",
    "    print(data[cols].head(5))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns:  ['Upfront Payment', 'Leg 1 Fixed Rate', 'Leg 1 Spread', 'Leg 1 Notional', 'Leg 2 Fixed Rate', 'Leg 2 Spread', 'Leg 2 Notional', 'Option Strike Price', 'Option Premium', 'Future Value Notional']\n",
      "Categorical columns:  ['Event', 'Cleared', 'Collateralization', 'End-User Exception', 'Bespoke', 'Block/Off facility', 'Execution Venue', 'UPI', 'Product', 'Contract Type', 'Upfront Payment Currency', 'Settlement Currency', 'Leg 1 Type', 'Leg 1 Floating Index', 'Leg 1 Designated Maturity', 'Leg 1 Day Count Convention', 'Leg 1 Notional Currency', 'Leg 1 Payment Frequency', 'Leg1 Reset Frequency', 'Leg 2 Type', 'Leg 2 Floating Index', 'Leg 2 Designated Maturity', 'Leg 2 Day Count Convention', 'Leg 2 Notional Currency', 'Leg 2 Payment Frequency', 'Leg 2 Reset Frequency', 'Embedded Option', 'Option Type', 'Option Family', 'Option Currency', 'Asset Class', 'Rpt ID', 'Prev Rpt ID', 'Contract Subtype']\n",
      "Other (non-categorized) columns:  ['Execution Timestamp', 'Dissemination Time', 'Effective Date', 'Maturity Date', 'Upfront Payment Date', 'Option Lockout Period', 'Option Expiration Date']\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 6: Divide columns to categorical & numerical\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Categorize columns based on the variables_info dictionary\n",
    "numerical_columns = [col for col, dtype in variables_info.items() if dtype in [\"int\", \"float\"] and col in data.columns]\n",
    "categorical_columns = [col for col, dtype in variables_info.items() if dtype in [\"string\", \"character\"] and col in data.columns]\n",
    "\n",
    "\n",
    "#TESTADE att ta bort att fylla i tomma värden men då funkar ej GAN modellen, kan visa vid tilfälle. MÅSTE HANTERAS\n",
    "# Fill missing values in numerical columns with their median\n",
    "for column in numerical_columns:\n",
    "    median_value = data[column].median()\n",
    "    data[column].fillna(median_value, inplace=True)\n",
    "\n",
    "# Fill missing values in categorical columns with their mode\n",
    "for column in categorical_columns:\n",
    "    mode_value = data[column].mode()[0]\n",
    "    data[column].fillna(mode_value, inplace=True)\n",
    "\n",
    "\n",
    "# Columns that have not been categorized as either numerical or categorical\n",
    "other_columns = [col for col in data.columns if col not in numerical_columns and col not in categorical_columns]\n",
    "\n",
    "\n",
    "print(\"Numerical columns: \", numerical_columns)\n",
    "print(\"Categorical columns: \", categorical_columns)\n",
    "print(\"Other (non-categorized) columns: \", other_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: 27 unique values\n",
      "Cleared: 4 unique values\n",
      "Collateralization: 4 unique values\n",
      "End-User Exception: 3 unique values\n",
      "Bespoke: 2 unique values\n",
      "Block/Off facility: 2 unique values\n",
      "Execution Venue: 4 unique values\n",
      "UPI: 4 unique values\n",
      "Product: 751 unique values\n",
      "Contract Type: 1 unique values\n",
      "Upfront Payment Currency: 2 unique values\n",
      "Settlement Currency: 27 unique values\n",
      "Leg 1 Type: 4 unique values\n",
      "Leg 1 Floating Index: 18 unique values\n",
      "Leg 1 Designated Maturity: 451 unique values\n",
      "Leg 1 Day Count Convention: 7 unique values\n",
      "Leg 1 Notional Currency: 27 unique values\n",
      "Leg 1 Payment Frequency: 9 unique values\n",
      "Leg1 Reset Frequency: 8 unique values\n",
      "Leg 2 Type: 4 unique values\n",
      "Leg 2 Floating Index: 230 unique values\n",
      "Leg 2 Designated Maturity: 451 unique values\n",
      "Leg 2 Day Count Convention: 6 unique values\n",
      "Leg 2 Notional Currency: 27 unique values\n",
      "Leg 2 Payment Frequency: 9 unique values\n",
      "Leg 2 Reset Frequency: 8 unique values\n",
      "Embedded Option: 2 unique values\n",
      "Option Type: 2 unique values\n",
      "Option Family: 2 unique values\n",
      "Option Currency: 1 unique values\n",
      "Asset Class: 1 unique values\n",
      "Rpt ID: 26500 unique values\n",
      "Prev Rpt ID: 45 unique values\n",
      "Contract Subtype: 4 unique values\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 7: List unique values count for each categorical column \n",
    "#   1. Used to understand how extensive the one hot encoding will be\n",
    "#   2. Reveals if any columns shuld be removed (too many unique values)\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "unique_counts = {}\n",
    "\n",
    "for column in categorical_columns:\n",
    "    unique_counts[column] = data[column].nunique()\n",
    "\n",
    "# Display the counts\n",
    "for column, count in unique_counts.items():\n",
    "    print(f\"{column}: {count} unique values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns: ['Event', 'Execution Timestamp', 'Dissemination Time', 'Cleared', 'Collateralization', 'End-User Exception', 'Bespoke', 'Block/Off facility', 'Execution Venue', 'UPI', 'Product', 'Contract Type', 'Effective Date', 'Maturity Date', 'Upfront Payment', 'Upfront Payment Currency', 'Upfront Payment Date', 'Settlement Currency', 'Leg 1 Designated Maturity', 'Leg 2 Designated Maturity', 'Embedded Option', 'Option Strike Price', 'Option Type', 'Option Family', 'Option Currency', 'Option Premium', 'Option Lockout Period', 'Option Expiration Date', 'Asset Class', 'Rpt ID', 'Prev Rpt ID', 'Contract Subtype']\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 8: Conditionally remove selected columns\n",
    "#   1. Specify the columns to be removed with a True/False flag in a dictionary.\n",
    "#   2. Use the drop method to remove columns marked as True.\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Dictionary of columns with True/False flags for removal\n",
    "\n",
    "# True = Remove\n",
    "columns_to_remove = {\n",
    "    \"Event\": True,\n",
    "    \"Execution Timestamp\": True,\n",
    "    \"Dissemination Time\": True,\n",
    "    \"Cleared\": True,\n",
    "    \"Collateralization\": True,\n",
    "    \"End-User Exception\": True,\n",
    "    \"Bespoke\": True,\n",
    "    \"Block/Off facility\": True,\n",
    "    \"Execution Venue\": True,\n",
    "    \"UPI\": True,\n",
    "    \"Product\": True,\n",
    "    \"Contract Type\": True,\n",
    "    \"Effective Date\": True, #OBS!!!! include new field that corresponds to contract lenght\n",
    "    \"Maturity Date\": True,\n",
    "    \"Upfront Payment\": True,\n",
    "    \"Upfront Payment Currency\": True,\n",
    "    \"Upfront Payment Date\": True,\n",
    "    \"Settlement Currency\": True,\n",
    "    \"Leg 1 Type\": False,\n",
    "    \"Leg 1 Fixed Rate\": False,\n",
    "    \"Leg 1 Floating Index\": False,\n",
    "    \"Leg 1 Designated Maturity\": True,\n",
    "    \"Leg 1 Spread\": False,\n",
    "    \"Leg 1 Day Count Convention\": False,\n",
    "    \"Leg 1 Notional\": False,\n",
    "    \"Leg 1 Notional Currency\": False,\n",
    "    \"Leg 1 Payment Frequency\": False,\n",
    "    \"Leg1 Reset Frequency\": False,\n",
    "    \"Leg 2 Type\": False,\n",
    "    \"Leg 2 Fixed Rate\": False,\n",
    "    \"Leg 2 Floating Index\": False,\n",
    "    \"Leg 2 Designated Maturity\": True,\n",
    "    \"Leg 2 Spread\": False,\n",
    "    \"Leg 2 Day Count Convention\": False,\n",
    "    \"Leg 2 Notional\": False,\n",
    "    \"Leg 2 Notional Currency\": False,\n",
    "    \"Leg 2 Payment Frequency\": False,\n",
    "    \"Leg 2 Reset Frequency\": False,\n",
    "    \"Embedded Option\": True,\n",
    "    \"Option Strike Price\": True,\n",
    "    \"Option Type\": True,\n",
    "    \"Option Family\": True,\n",
    "    \"Option Currency\": True,\n",
    "    \"Option Premium\": True,\n",
    "    \"Option Lockout Period\": True,\n",
    "    \"Option Expiration Date\": True,\n",
    "    \"Asset Class\": True,\n",
    "    \"Rpt ID\": True,\n",
    "    \"Prev Rpt ID\": True,\n",
    "    \"Future Value Notional\": False,\n",
    "    \"Contract Subtype\": True\n",
    "}\n",
    "\n",
    "# Remove columns marked as True\n",
    "removed_columns = [col for col, remove in columns_to_remove.items() if remove and col in data.columns]\n",
    "data.drop(removed_columns, axis=1, inplace=True)\n",
    "\n",
    "# Update the list of numerical columns\n",
    "numerical_columns = [col for col in numerical_columns if col not in removed_columns]\n",
    "categorical_columns = [col for col in categorical_columns if col not in removed_columns]\n",
    "\n",
    "\n",
    "# Display the list of removed columns\n",
    "print(\"Removed columns:\", removed_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 9: Date/timestamp management\n",
    "#   1. Denna modul ska hantera datum per TriOptimas instruktioner via mejl\n",
    "#--------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to /Users/valdemarhane/Documents/GitHub/ME2313-T2/ME2313-T2/Cleaned Data/RT.IRS_Clean_v2_RandomModel.csv\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 10: Save Cleaned Preprocessed Data to CSV\n",
    "#   1. Used for simple random generating model\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Define the output file path for the cleaned data\n",
    "cleaned_data_file_path = os.path.join(current_directory, \"Cleaned Data/RT.IRS_Clean_v2_RandomModel.csv\")\n",
    "\n",
    "# Save the cleaned data to a CSV file\n",
    "data.to_csv(cleaned_data_file_path, index=False)\n",
    "\n",
    "print(\"Cleaned data saved to\", cleaned_data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min values:\n",
      " Leg 1 Fixed Rate        -1.0\n",
      "Leg 1 Spread            -1.0\n",
      "Leg 1 Notional          -1.0\n",
      "Leg 2 Fixed Rate        -1.0\n",
      "Leg 2 Spread            -1.0\n",
      "Leg 2 Notional          -1.0\n",
      "Future Value Notional   -1.0\n",
      "dtype: float64\n",
      "Max values:\n",
      " Leg 1 Fixed Rate         1.0\n",
      "Leg 1 Spread             1.0\n",
      "Leg 1 Notional           1.0\n",
      "Leg 2 Fixed Rate         1.0\n",
      "Leg 2 Spread             1.0\n",
      "Leg 2 Notional           1.0\n",
      "Future Value Notional   -1.0\n",
      "dtype: float64\n",
      "Any value outside the [-1, 1] range: 7\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 11: Normalization for machine learning suitability\n",
    "#   1. Normalize numerical features to ensure they have a similar scale.\n",
    "#   2. One-hot encode categorical features to convert them into a format suitable for the machine learning model.\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Normalize numerical features using RobustScaler\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "# Check the min and max values\n",
    "min_values = data[numerical_columns].min()\n",
    "max_values = data[numerical_columns].max()\n",
    "\n",
    "# Check if any value is below -1 or above 1\n",
    "outside_range = (min_values < -1).count() or (max_values > 1).count()\n",
    "\n",
    "# Print results\n",
    "print(\"Min values:\\n\", min_values)\n",
    "print(\"Max values:\\n\", max_values)\n",
    "print(\"Any value outside the [-1, 1] range:\", outside_range)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "data_encoded = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 12: Pickle that big boi data for later use in GAN model\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "# Ensure the directory \"Processed data\" exists\n",
    "if not os.path.exists(\"Processed data\"):\n",
    "    os.makedirs(\"Processed data\")\n",
    "\n",
    "# Save the DataFrame as a pickled file\n",
    "current_directory = os.getcwd()\n",
    "data_encoded.to_csv(\"Processed data/data_encoded.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
