{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mg/_0j_111n661ccjxlkkzpn6xh0000gn/T/ipykernel_5148/2513161849.py:22: DtypeWarning: Columns (9,14,19,22,24,29,32,34,39,40,41,42,43,44,45,48,52,75,87,91,99,110,112,113,135,139,140,141,143,145,156,157) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(input_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved to /Users/ollepyk/Documents/GitHub/ME2313-T2/Cleaned Data/RT.IRS_Clean_v1.csv\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 1: Imports RT.IRS_data.csv and cleans it by removing all rows which does  not have \n",
    "# data in the \"Event\"-column. Further it removes all headers and corresponding \n",
    "# columns which is empty (no data).\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths using relative paths\n",
    "input_file_path = \"Categorized Data/RT.IRS_Data.csv\"\n",
    "output_file_path = \"Cleaned Data/RT.IRS_Clean_v1.csv\"\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Construct absolute file paths\n",
    "input_file_path = os.path.join(current_directory, input_file_path)\n",
    "output_file_path = os.path.join(current_directory, output_file_path)\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(input_file_path)\n",
    "\n",
    "# Remove rows where the \"Event\" column is empty\n",
    "data = data.dropna(subset=['Event'])\n",
    "\n",
    "# Remove columns where all values are NaN after removing empty rows\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "# Remove rows where \"Event\" column starts with two numbers\n",
    "data = data[~data['Event'].astype(str).str.match(r'^\\d{2}')]\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Data cleaned and saved to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned, sorted, and saved to /Users/ollepyk/Documents/GitHub/ME2313-T2/Cleaned Data/RT.IRS_Clean_v1.csv\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 2: Sort the rows based on the \"Event\" column \n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Sort the rows based on the \"Event\" column\n",
    "data = data.sort_values(by='Event')\n",
    "\n",
    "# Save the cleaned and sorted data to a new CSV file\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Data cleaned, sorted, and saved to\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables defined.\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 3: Define parameters\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Define the variables from the second sheet\n",
    "variables_info = {\n",
    "    \"Event\": \"string\",\n",
    "    \"Execution Timestamp\": \"datetime\",\n",
    "    \"Dissemination Time\": \"datetime\",\n",
    "    \"Cleared\": \"string\",\n",
    "    \"Collateralization\": \"string\",\n",
    "    \"End-User Exception\": \"string\",\n",
    "    \"Bespoke\": \"character\",\n",
    "    \"Block/Off facility\": \"character\",\n",
    "    \"Execution Venue\": \"string\",\n",
    "    \"UPI\": \"string\",\n",
    "    \"Fixed Float Swap\": \"string\",\n",
    "    \"Contract Type\": \"string\",\n",
    "    \"Effective Date\": \"date\",\n",
    "    \"Maturity Date\": \"date\",\n",
    "    \"Upfront Payment\": \"int\",\n",
    "    \"Upfront Payment Currency\": \"string\",\n",
    "    \"Upfront Payment Date\": \"date\",\n",
    "    \"Settlement Currency\": \"string\",\n",
    "    \"Leg 1 Type\": \"string\",\n",
    "    \"Leg 1 Fixed Rate\": \"int\",\n",
    "    \"Leg 1 Floating Index\": \"string\",\n",
    "    \"Leg 1 Designated Maturity\": \"string\",\n",
    "    \"Leg 1 Spread\": \"float\",\n",
    "    \"Leg 1 Day Count Convention\": \"string\",\n",
    "    \"Leg 1 Notional\": \"int\",\n",
    "    \"Leg 1 Notional Currency\": \"string\",\n",
    "    \"Leg 1 Payment Frequency\": \"string\",\n",
    "    \"Leg1 Reset Frequency\": \"string\",\n",
    "    \"Leg 2 Type\": \"string\",\n",
    "    \"Leg 2 Fixed Rate\": \"float\",\n",
    "    \"Leg 2 Floating Index\": \"string\",\n",
    "    \"Leg 2 Designated Maturity\": \"string\",\n",
    "    \"Leg 2 Spread\": \"float\",\n",
    "    \"Leg 2 Day Count Convention\": \"string\",\n",
    "    \"Leg 2 Notional\": \"float\",\n",
    "    \"Leg 2 Notional Currency\": \"string\",\n",
    "    \"Leg 2 Payment Frequency\": \"string\",\n",
    "    \"Leg 2 Reset Frequency\": \"string\",\n",
    "    \"Embedded Option\": \"character\",\n",
    "    \"Option Strike Price\": \"float\",\n",
    "    \"Option Type\": \"string\",\n",
    "    \"Option Family\": \"string\",\n",
    "    \"Option Currency\": \"string\",\n",
    "    \"Option Premium\": \"float\",\n",
    "    \"Option Lockout Period\": \"date\",\n",
    "    \"Option Expiration Date\": \"date\",\n",
    "    \"Asset Class\": \"string\",\n",
    "    \"Rpt ID\": \"string\",\n",
    "    \"Prev Rpt ID\": \"string\",\n",
    "    \"Future Value Notional\": \"float\",\n",
    "    \"Contract Subtype\": \"string\"\n",
    "}\n",
    "\n",
    "print(\"Variables defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data adjusted and saved to /Users/ollepyk/Documents/GitHub/ME2313-T2/Cleaned Data/RT.IRS_Clean_vX.csv\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 4: Adjust columns according to variables_info and save to CSV\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "for column, data_type in variables_info.items():\n",
    "    if column in data.columns:\n",
    "        if data_type == \"string\":\n",
    "            data[column] = data[column].astype(str)\n",
    "        elif data_type == \"int\":\n",
    "            # Convert to numeric with NaN for non-convertible values\n",
    "            data[column] = pd.to_numeric(data[column], errors='coerce')\n",
    "            # Optional: Fill NaN with a placeholder like 0 or -1\n",
    "            # data[column] = data[column].fillna(0).astype('Int64')\n",
    "        elif data_type == \"float\":\n",
    "            data[column] = pd.to_numeric(data[column], errors='coerce')\n",
    "        elif data_type == \"datetime\":\n",
    "            data[column] = pd.to_datetime(data[column], errors='coerce')\n",
    "        elif data_type == \"date\":\n",
    "            data[column] = pd.to_datetime(data[column], errors='coerce').dt.date\n",
    "        # Add more conditions as needed for other data types\n",
    "\n",
    "\n",
    "# Define the output file path for the cleaned data\n",
    "output_file_path = os.path.join(current_directory, \"Cleaned Data/RT.IRS_Clean_v2.csv\")\n",
    "\n",
    "# Save the adjusted data to a CSV file\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Data adjusted and saved to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: string\n",
      "            Event    Cleared       Collateralization End-User Exception  \\\n",
      "18570  Allocation    Cleared  One-Way Collateralized                nan   \n",
      "18569  Allocation    Cleared  One-Way Collateralized                nan   \n",
      "23513  Allocation    Cleared  One-Way Collateralized                nan   \n",
      "23515  Allocation    Cleared  One-Way Collateralized                nan   \n",
      "33310   Amendment  Uncleared        Uncollateralized           End-user   \n",
      "\n",
      "         Execution Venue                UPI     Contract Type  \\\n",
      "18570  Off Facility Swap                nan  InterestRateSwap   \n",
      "18569  Off Facility Swap                nan  InterestRateSwap   \n",
      "23513  Off Facility Swap                nan  InterestRateSwap   \n",
      "23515  Off Facility Swap                nan  InterestRateSwap   \n",
      "33310  Off Facility Swap  InterestRate prod          CapFloor   \n",
      "\n",
      "      Upfront Payment Currency Settlement Currency Leg 1 Type  ...  \\\n",
      "18570                      nan                 USD      Float  ...   \n",
      "18569                      nan                 USD      Fixed  ...   \n",
      "23513                      nan                 USD      Fixed  ...   \n",
      "23515                      nan                 USD      Float  ...   \n",
      "33310                      USD                 USD      Fixed  ...   \n",
      "\n",
      "      Leg 2 Notional Currency Leg 2 Payment Frequency Leg 2 Reset Frequency  \\\n",
      "18570                     USD                      6M                   nan   \n",
      "18569                     USD                      3M                     3   \n",
      "23513                     USD                      3M                     3   \n",
      "23515                     USD                      6M                   nan   \n",
      "33310                     nan                     nan                   nan   \n",
      "\n",
      "      Option Type Option Family Option Currency    Asset Class       Rpt ID  \\\n",
      "18570         nan           nan             nan  Interest Rate  IRS48266001   \n",
      "18569         nan           nan             nan  Interest Rate  IRS48265989   \n",
      "23513         nan           nan             nan  Interest Rate  IRS48225527   \n",
      "23515         nan           nan             nan  Interest Rate  IRS48225530   \n",
      "33310         Cap      American             USD  Interest Rate  IRS13003270   \n",
      "\n",
      "      Prev Rpt ID Contract Subtype  \n",
      "18570         nan             SWAP  \n",
      "18569         nan             SWAP  \n",
      "23513         nan             SWAP  \n",
      "23515         nan             SWAP  \n",
      "33310         nan              nan  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "\n",
      "Data Type: datetime\n",
      "      Execution Timestamp  Dissemination Time\n",
      "18570 2022-10-11 19:43:52 2022-10-11 19:43:52\n",
      "18569 2022-10-11 19:43:52 2022-10-11 19:43:52\n",
      "23513 2022-10-03 21:08:06 2022-10-03 21:08:06\n",
      "23515 2022-10-03 21:08:06 2022-10-03 21:08:06\n",
      "33310 2014-07-08 15:25:00 2014-07-08 15:25:00\n",
      "\n",
      "\n",
      "Data Type: character\n",
      "      Bespoke Block/Off facility Embedded Option\n",
      "18570       N                  N             NaN\n",
      "18569       N                  N             NaN\n",
      "23513       N                  N             NaN\n",
      "23515       N                  N             NaN\n",
      "33310       N                  N               Y\n",
      "\n",
      "\n",
      "Data Type: date\n",
      "      Effective Date Maturity Date Upfront Payment Date Option Lockout Period  \\\n",
      "18570     2013-06-19    2023-06-19                  NaT                   NaT   \n",
      "18569     2013-06-19    2023-06-19                  NaT                   NaT   \n",
      "23513     2013-06-19    2023-06-19                  NaT                   NaT   \n",
      "23515     2013-06-19    2023-06-19                  NaT                   NaT   \n",
      "33310     2008-07-24    2016-04-04           2010-03-08            2010-09-09   \n",
      "\n",
      "      Option Expiration Date  \n",
      "18570                    NaT  \n",
      "18569                    NaT  \n",
      "23513                    NaT  \n",
      "23515                    NaT  \n",
      "33310             2010-08-08  \n",
      "\n",
      "\n",
      "Data Type: int\n",
      "       Upfront Payment  Leg 1 Fixed Rate  Leg 1 Notional\n",
      "18570              0.0               0.0        990000.0\n",
      "18569              0.0               2.0        990000.0\n",
      "23513              0.0               2.0        990000.0\n",
      "23515              0.0               0.0        990000.0\n",
      "33310            345.0             200.0      10000000.0\n",
      "\n",
      "\n",
      "Data Type: float\n",
      "       Leg 1 Spread  Leg 2 Fixed Rate  Leg 2 Spread  Leg 2 Notional  \\\n",
      "18570           0.0               2.0           0.0        990000.0   \n",
      "18569           0.0               0.0           0.0        990000.0   \n",
      "23513           0.0               0.0           0.0        990000.0   \n",
      "23515           0.0               2.0           0.0        990000.0   \n",
      "33310         250.0               0.0           0.0             0.0   \n",
      "\n",
      "       Option Strike Price  Option Premium  Future Value Notional  \n",
      "18570                  0.0             0.0                    0.0  \n",
      "18569                  0.0             0.0                    0.0  \n",
      "23513                  0.0             0.0                    0.0  \n",
      "23515                  0.0             0.0                    0.0  \n",
      "33310                  0.0        100000.0                    NaN  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 5: Display DataFrame rows separated by data types\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Group columns by their data types\n",
    "columns_by_type = {}\n",
    "for col, dtype in variables_info.items():\n",
    "    if col in data.columns:\n",
    "        columns_by_type.setdefault(dtype, []).append(col)\n",
    "\n",
    "# Print the top 5 rows for each data type\n",
    "for dtype, cols in columns_by_type.items():\n",
    "    print(f\"Data Type: {dtype}\")\n",
    "    print(data[cols].head(5))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with remaining missing values:  ['Effective Date', 'Maturity Date', 'Upfront Payment Date', 'Option Lockout Period', 'Option Expiration Date']\n",
      "Numerical columns:  ['Upfront Payment', 'Leg 1 Fixed Rate', 'Leg 1 Spread', 'Leg 1 Notional', 'Leg 2 Fixed Rate', 'Leg 2 Spread', 'Leg 2 Notional', 'Option Strike Price', 'Option Premium', 'Future Value Notional']\n",
      "Categorical columns:  ['Event', 'Cleared', 'Collateralization', 'End-User Exception', 'Bespoke', 'Block/Off facility', 'Execution Venue', 'UPI', 'Contract Type', 'Upfront Payment Currency', 'Settlement Currency', 'Leg 1 Type', 'Leg 1 Floating Index', 'Leg 1 Designated Maturity', 'Leg 1 Day Count Convention', 'Leg 1 Notional Currency', 'Leg 1 Payment Frequency', 'Leg1 Reset Frequency', 'Leg 2 Type', 'Leg 2 Floating Index', 'Leg 2 Designated Maturity', 'Leg 2 Day Count Convention', 'Leg 2 Notional Currency', 'Leg 2 Payment Frequency', 'Leg 2 Reset Frequency', 'Embedded Option', 'Option Type', 'Option Family', 'Option Currency', 'Asset Class', 'Rpt ID', 'Prev Rpt ID', 'Contract Subtype']\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 6: Divide columns to cat & num\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Categorize columns based on the variables_info dictionary\n",
    "numerical_columns = [col for col, dtype in variables_info.items() if dtype in [\"int\", \"float\"] and col in data.columns]\n",
    "categorical_columns = [col for col, dtype in variables_info.items() if dtype in [\"string\", \"character\"] and col in data.columns]\n",
    "\n",
    "# Fill missing values in numerical columns with their median\n",
    "for column in numerical_columns:\n",
    "    median_value = data[column].median()\n",
    "    data[column].fillna(median_value, inplace=True)\n",
    "\n",
    "# Fill missing values in categorical columns with their mode\n",
    "for column in categorical_columns:\n",
    "    mode_value = data[column].mode()[0]\n",
    "    data[column].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Identify columns with remaining missing values\n",
    "columns_with_missing_values = data.columns[data.isnull().any()]\n",
    "\n",
    "print(\"Columns with remaining missing values: \", columns_with_missing_values.tolist())\n",
    "print(\"Numerical columns: \", numerical_columns)\n",
    "print(\"Categorical columns: \", categorical_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: 27 unique values\n",
      "Cleared: 4 unique values\n",
      "Collateralization: 4 unique values\n",
      "End-User Exception: 3 unique values\n",
      "Bespoke: 2 unique values\n",
      "Block/Off facility: 2 unique values\n",
      "Execution Venue: 4 unique values\n",
      "UPI: 4 unique values\n",
      "Contract Type: 4 unique values\n",
      "Upfront Payment Currency: 2 unique values\n",
      "Settlement Currency: 27 unique values\n",
      "Leg 1 Type: 5 unique values\n",
      "Leg 1 Floating Index: 46 unique values\n",
      "Leg 1 Designated Maturity: 453 unique values\n",
      "Leg 1 Day Count Convention: 7 unique values\n",
      "Leg 1 Notional Currency: 27 unique values\n",
      "Leg 1 Payment Frequency: 10 unique values\n",
      "Leg1 Reset Frequency: 8 unique values\n",
      "Leg 2 Type: 5 unique values\n",
      "Leg 2 Floating Index: 230 unique values\n",
      "Leg 2 Designated Maturity: 451 unique values\n",
      "Leg 2 Day Count Convention: 7 unique values\n",
      "Leg 2 Notional Currency: 28 unique values\n",
      "Leg 2 Payment Frequency: 10 unique values\n",
      "Leg 2 Reset Frequency: 8 unique values\n",
      "Embedded Option: 2 unique values\n",
      "Option Type: 2 unique values\n",
      "Option Family: 3 unique values\n",
      "Option Currency: 2 unique values\n",
      "Asset Class: 1 unique values\n",
      "Rpt ID: 27323 unique values\n",
      "Prev Rpt ID: 45 unique values\n",
      "Contract Subtype: 4 unique values\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 7: List unique values count for each categorical column \n",
    "#   1. Used to understand how extensive the one hot encoding will be\n",
    "#   2. Reveals if any columns shuld be removed (too many unique values)\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "unique_counts = {}\n",
    "\n",
    "for column in categorical_columns:\n",
    "    unique_counts[column] = data[column].nunique()\n",
    "\n",
    "# Display the counts\n",
    "for column, count in unique_counts.items():\n",
    "    print(f\"{column}: {count} unique values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns: ['UPI', 'Rpt ID']\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 8: Conditionally remove selected columns\n",
    "#   1. Specify the columns to be removed with a True/False flag in a dictionary.\n",
    "#   2. Use the drop method to remove columns marked as True.\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Dictionary of columns with True/False flags for removal\n",
    "columns_to_remove = {\n",
    "    \"Event\": False,\n",
    "    \"Execution Timestamp\": False,\n",
    "    \"Dissemination Time\": False,\n",
    "    \"Cleared\": False,\n",
    "    \"Collateralization\": False,\n",
    "    \"End-User Exception\": False,\n",
    "    \"Bespoke\": False,\n",
    "    \"Block/Off facility\": False,\n",
    "    \"Execution Venue\": False,\n",
    "    \"UPI\": True,\n",
    "    \"Fixed Float Swap\": False,\n",
    "    \"Contract Type\": False,\n",
    "    \"Effective Date\": False,\n",
    "    \"Maturity Date\": False,\n",
    "    \"Upfront Payment\": False,\n",
    "    \"Upfront Payment Currency\": False,\n",
    "    \"Upfront Payment Date\": False,\n",
    "    \"Settlement Currency\": False,\n",
    "    \"Leg 1 Type\": False,\n",
    "    \"Leg 1 Fixed Rate\": False,\n",
    "    \"Leg 1 Floating Index\": False,\n",
    "    \"Leg 1 Designated Maturity\": False,\n",
    "    \"Leg 1 Spread\": False,\n",
    "    \"Leg 1 Day Count Convention\": False,\n",
    "    \"Leg 1 Notional\": False,\n",
    "    \"Leg 1 Notional Currency\": False,\n",
    "    \"Leg 1 Payment Frequency\": False,\n",
    "    \"Leg1 Reset Frequency\": False,\n",
    "    \"Leg 2 Type\": False,\n",
    "    \"Leg 2 Fixed Rate\": False,\n",
    "    \"Leg 2 Floating Index\": False,\n",
    "    \"Leg 2 Designated Maturity\": False,\n",
    "    \"Leg 2 Spread\": False,\n",
    "    \"Leg 2 Day Count Convention\": False,\n",
    "    \"Leg 2 Notional\": False,\n",
    "    \"Leg 2 Notional Currency\": False,\n",
    "    \"Leg 2 Payment Frequency\": False,\n",
    "    \"Leg 2 Reset Frequency\": False,\n",
    "    \"Embedded Option\": False,\n",
    "    \"Option Strike Price\": False,\n",
    "    \"Option Type\": False,\n",
    "    \"Option Family\": False,\n",
    "    \"Option Currency\": False,\n",
    "    \"Option Premium\": False,\n",
    "    \"Option Lockout Period\": False,\n",
    "    \"Option Expiration Date\": False,\n",
    "    \"Asset Class\": False,\n",
    "    \"Rpt ID\": True,\n",
    "    \"Prev Rpt ID\": False,\n",
    "    \"Future Value Notional\": False,\n",
    "    \"Contract Subtype\": False\n",
    "}\n",
    "\n",
    "# Remove columns marked as True\n",
    "removed_columns = [col for col, remove in columns_to_remove.items() if remove and col in data.columns]\n",
    "data.drop(removed_columns, axis=1, inplace=True)\n",
    "\n",
    "# Display the list of removed columns\n",
    "print(\"Removed columns:\", removed_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 9: Date/timestamp management\n",
    "#   1. Convert \"Maturity Date\" and \"Execution Timestamp\" columns to datetime format.\n",
    "#   2. Extract relevant features from these datetime columns.\n",
    "#   3. Convert derived date features to categorical values.\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "# Convert \"Maturity Date\" and \"Execution Timestamp\" columns to datetime format\n",
    "#data[\"Maturity Date\"] = pd.to_datetime(data[\"Maturity Date\"], errors='coerce')\n",
    "#data[\"Execution Timestamp\"] = pd.to_datetime(data[\"Execution Timestamp\"], errors='coerce')\n",
    "\n",
    "# Extract features from \"Maturity Date\"\n",
    "#data[\"Maturity_Day\"] = data[\"Maturity Date\"].dt.day\n",
    "#data[\"Maturity_Month\"] = data[\"Maturity Date\"].dt.month\n",
    "#data[\"Maturity_Year\"] = data[\"Maturity Date\"].dt.year\n",
    "\n",
    "# Extract features from \"Execution Timestamp\"\n",
    "#data[\"Execution_Day\"] = data[\"Execution Timestamp\"].dt.day\n",
    "#data[\"Execution_Month\"] = data[\"Execution Timestamp\"].dt.month\n",
    "#data[\"Execution_Year\"] = data[\"Execution Timestamp\"].dt.year\n",
    "\n",
    "# Convert the derived features to strings, making them categorical\n",
    "#categorical_columns = [\"Maturity_Day\", \"Maturity_Month\", \"Maturity_Year\", \n",
    "#                       \"Execution_Day\", \"Execution_Month\", \"Execution_Year\"]\n",
    "\n",
    "#for col in categorical_columns:\n",
    "#    data[col] = data[col].astype(str)\n",
    "\n",
    "# Drop the original datetime columns\n",
    "#data.drop([\"Maturity Date\", \"Execution Timestamp\"], axis=1, inplace=True)\n",
    "\n",
    "# Display the first few rows with the new features\n",
    "#data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27326, 8822),\n",
       "       Execution Timestamp  Dissemination Time  Upfront Payment  \\\n",
       " 18570 2022-10-11 19:43:52 2022-10-11 19:43:52         0.496424   \n",
       " 18569 2022-10-11 19:43:52 2022-10-11 19:43:52         0.496424   \n",
       " 23513 2022-10-03 21:08:06 2022-10-03 21:08:06         0.496424   \n",
       " 23515 2022-10-03 21:08:06 2022-10-03 21:08:06         0.496424   \n",
       " 33310 2014-07-08 15:25:00 2014-07-08 15:25:00         0.496424   \n",
       " \n",
       "        Leg 1 Fixed Rate  Leg 1 Spread  Leg 1 Notional  Leg 2 Fixed Rate  \\\n",
       " 18570          0.002164      0.000000    9.979034e-07          0.013324   \n",
       " 18569          0.008587      0.000000    9.979034e-07          0.003358   \n",
       " 23513          0.008587      0.000000    9.979034e-07          0.003358   \n",
       " 23515          0.002164      0.000000    9.979034e-07          0.013324   \n",
       " 33310          0.644479      0.753012    1.007988e-05          0.003358   \n",
       " \n",
       "        Leg 2 Spread  Leg 2 Notional  Option Strike Price  ...  \\\n",
       " 18570           0.0    9.979084e-07                  0.0  ...   \n",
       " 18569           0.0    9.979084e-07                  0.0  ...   \n",
       " 23513           0.0    9.979084e-07                  0.0  ...   \n",
       " 23515           0.0    9.979084e-07                  0.0  ...   \n",
       " 33310           0.0    0.000000e+00                  0.0  ...   \n",
       " \n",
       "        Prev Rpt ID_IRS41457129  Prev Rpt ID_IRS41457134  \\\n",
       " 18570                    False                    False   \n",
       " 18569                    False                    False   \n",
       " 23513                    False                    False   \n",
       " 23515                    False                    False   \n",
       " 33310                    False                    False   \n",
       " \n",
       "        Prev Rpt ID_IRS41457136  Prev Rpt ID_IRS41457137  \\\n",
       " 18570                    False                    False   \n",
       " 18569                    False                    False   \n",
       " 23513                    False                    False   \n",
       " 23515                    False                    False   \n",
       " 33310                    False                    False   \n",
       " \n",
       "        Prev Rpt ID_IRS41457138  Prev Rpt ID_IRS41457140  Prev Rpt ID_nan  \\\n",
       " 18570                    False                    False             True   \n",
       " 18569                    False                    False             True   \n",
       " 23513                    False                    False             True   \n",
       " 23515                    False                    False             True   \n",
       " 33310                    False                    False             True   \n",
       " \n",
       "        Contract Subtype_Fixed-Float  Contract Subtype_SWAP  \\\n",
       " 18570                         False                   True   \n",
       " 18569                         False                   True   \n",
       " 23513                         False                   True   \n",
       " 23515                         False                   True   \n",
       " 33310                         False                  False   \n",
       " \n",
       "        Contract Subtype_nan  \n",
       " 18570                 False  \n",
       " 18569                 False  \n",
       " 23513                 False  \n",
       " 23515                 False  \n",
       " 33310                  True  \n",
       " \n",
       " [5 rows x 8822 columns])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 10: Normalization for machine learning suitability\n",
    "#   1. Normalize numerical features to ensure they have a similar scale.\n",
    "#   2. One-hot encode categorical features to convert them into a format suitable for the machine learning model.\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = MinMaxScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "data_encoded = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Display the shape and first few rows of the transformed dataset\n",
    "data_encoded_shape = data_encoded.shape\n",
    "data_encoded_head = data_encoded.head()\n",
    "\n",
    "data_encoded_shape, data_encoded_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Module 11: Pickle that big boi data for later use in GAN model\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Ensure the directory \"Processed data\" exists\n",
    "if not os.path.exists(\"Processed data\"):\n",
    "    os.makedirs(\"Processed data\")\n",
    "\n",
    "# Save the DataFrame as a pickled file\n",
    "with open(\"Processed data/data_encoded.pkl\", \"wb\") as file:\n",
    "    pickle.dump(data_encoded, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
